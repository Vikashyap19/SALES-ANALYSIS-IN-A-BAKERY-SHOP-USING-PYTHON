{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mlxtend.frequent_patterns import apriori, association_rules\nimport networkx as nx\n\n# Load the dataset\nfile_path = \"\"  # \ndf = pd.read_csv(file_path)\n\n# Basic Information about the dataset\nprint(\"Dataset Shape:\", df.shape)\nprint(\"\\nDataset Info:\")\ndf.info()\nprint(\"\\nFirst 10 Rows of the Dataset:\")\nprint(df.head(10))\n\n# Check number of unique items in the 'article' column\nprint(\"\\nNumber of unique items:\", df['article'].nunique())\nprint(\"\\nList of unique items:\")\nprint(df['article'].unique())\n\n# Check how many rows have 'NONE' as an item\nnone_count = (df['article'] == \"NONE\").sum()\nprint(f\"\\nNumber of rows with 'NONE' as an article: {none_count}\")\n\n# Visualize the 20 most sold items\nprint(\"\\n20 Most Sold Items at the Shop:\")\ntop_items = df['article'].value_counts().head(20)\nplt.figure(figsize=(16, 7))\nsns.barplot(x=top_items.index, y=top_items.values, palette=\"viridis\")\nplt.xlabel('Article')\nplt.ylabel('Number of Transactions')\nplt.title('20 Most Sold Items at the Shop')\nplt.xticks(rotation=45)\nplt.show()\n\n# Prepare the dataset for Market Basket Analysis\n# Step 1: Group data by transaction and article, then create a pivot table\nprint(\"\\nPreparing data for Market Basket Analysis...\")\nhot_encoded_df = df.groupby(['ticket_number', 'article'])['article'].count().unstack().fillna(0)\n\n# Step 2: Convert counts into binary format (0/1) for presence/absence of an item\nhot_encoded_df = (hot_encoded_df > 0).astype(bool)\nprint(\"\\nHot Encoded Data (First 5 rows):\")\nprint(hot_encoded_df.head())\n\n# Apply Apriori algorithm to find frequent itemsets\nmin_support = 0.01  # Minimum support threshold\nprint(\"\\nApplying Apriori Algorithm...\")\nfrequent_itemsets = apriori(hot_encoded_df, min_support=min_support, use_colnames=True)\nprint(\"\\nFrequent Itemsets (Top 10):\")\nprint(frequent_itemsets.head(10))\n\n# Generate Association Rules\nmin_lift = 1  # Minimum lift threshold\nprint(\"\\nGenerating Association Rules...\")\nrules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=min_lift)\n\n# Sort rules by confidence\nrules.sort_values('confidence', ascending=False, inplace=True)\n\n# Display top 10 association rules\nprint(\"\\nTop 10 Association Rules:\")\nprint(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10))\n\n# Visualize the association rules using a network graph\nprint(\"\\nVisualizing Association Rules...\")\nG = nx.from_pandas_edgelist(\n    rules, 'antecedents', 'consequents', \n    edge_attr=['support', 'confidence', 'lift']\n)\n\nplt.figure(figsize=(12, 8))\npos = nx.spring_layout(G)\nnx.draw(\n    G, pos, with_labels=True, node_size=3000, node_color=\"lightblue\", \n    font_size=10, font_color=\"black\", edge_color=\"gray\"\n)\nplt.title(\"Association Rules Network\")\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}